{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng class embedding vị trí cho chữ cái"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, seq_len= 500, dropout= 0.2):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        pos = torch.arange(0, seq_len).reshape(seq_len, 1)\n",
    "        denominator = torch.Tensor( 10000**(torch.arange(0, embed_dim, 2)) / embed_dim)\n",
    "        \n",
    "        pos_embedding = torch.zeros((seq_len, embed_dim if embed_dim%2== 0 else (embed_dim + 1)))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos*denominator)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos*denominator)\n",
    "\n",
    "        pos_embedding = pos_embedding[:, :embed_dim]\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor):\n",
    "        batch_size = token_embedding.size(0)\n",
    "        seq_len = token_embedding.size(1)\n",
    "        pos_embedding = self.pos_embedding[:seq_len, :].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "        return self.dropout(pos_embedding + token_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng class embedding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizedEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size):\n",
    "        super(TokenizedEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings= vocab_size, embedding_dim= embed_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.embed_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lớp Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnEncoder(nn.Module):\n",
    "    def __init__(self, src_vocab, embed_dim, hidden_dim, n_layers, dropout, DEVICE):\n",
    "        super(RnnEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding = TokenizedEmbedding(\n",
    "            embed_dim= embed_dim,\n",
    "            vocab_size= len(src_vocab)\n",
    "            )\n",
    "        \n",
    "        self.rnn_layer = nn.GRU(\n",
    "            input_size= embed_dim, \n",
    "            hidden_size= hidden_dim,\n",
    "            num_layers= n_layers,\n",
    "            batch_first= True\n",
    "            )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(normalized_shape= hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features= hidden_dim,\n",
    "            out_features= hidden_dim,\n",
    "            device= DEVICE\n",
    "            )\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x là câu đầu vào [batch_size, seq_len]\n",
    "        x = self.embedding(x) # [batch_size, seq_len, embed_dim]\n",
    "        x, hn = self.rnn_layer(x) # hn.shape = [n_layers, batch_size, hidden_dim]\n",
    "        hn = self.norm(hn)\n",
    "        hn = self.relu(hn)\n",
    "        hn = self.dropout(hn)\n",
    "        hn = self.fc(hn)# hn.shape = [n_layers, batch_size, hidden_dim]\n",
    "        return x, hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lớp Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnDecoder(nn.Module):\n",
    "    def __init__(self, tgt_vocab, hidden_dim, n_layers, dropout, SOS_token, DEVICE):\n",
    "        super(RnnDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = TokenizedEmbedding(\n",
    "            embed_dim= hidden_dim,\n",
    "            vocab_size= len(tgt_vocab)\n",
    "            )\n",
    "        \n",
    "        self.rnn_layer = nn.GRU(\n",
    "            input_size= hidden_dim, \n",
    "            hidden_size= hidden_dim,\n",
    "            num_layers= n_layers,\n",
    "            batch_first= True\n",
    "            )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features= hidden_dim, \n",
    "            out_features= len(tgt_vocab)\n",
    "        )        \n",
    "\n",
    "        self.norm = nn.LayerNorm(normalized_shape= hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.device = DEVICE        \n",
    "        self.sos_token = SOS_token\n",
    "\n",
    "    def forward(self, encoder_outputs, context, target_tensor=None):\n",
    "        # encoder_outputs: đầu ra của encoder cho toàn bộ chuỗi đầu vào [batch_size, seq_len, hidden_dim]\n",
    "        # encoder_final_hidden: hidden state cuối cùng của encoder [n_layers, batch_size, hidden_dim]\n",
    "        # target_tensor: chuỗi target thực tế (sử dụng cho teacher forcing)\n",
    "        \n",
    "        max_len = target_tensor.size(1) # Lấy ra độ dài câu mục tiêu\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        # decoder_input.shape = [batch_size, 1, hidden_dim]\n",
    "        decoder_input = torch.empty((batch_size, 1), dtype= torch.long, device= self.device).fill_(self.sos_token)\n",
    "        decoder_hidden = context\n",
    "        decoder_outputs = []\n",
    "        decoder_outputs.append(self.embedding(decoder_input))\n",
    "        \n",
    "        for i in range(1, max_len):\n",
    "            # decoder_output.shape = [batch_size, seq_len= 1, hidden_dim]\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                decoder_input = decoder_output.detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim= 1)\n",
    "        decoder_outputs = self.norm(decoder_outputs)\n",
    "        decoder_outputs = self.dropout(decoder_outputs)\n",
    "        decoder_outputs = self.fc(decoder_outputs) # [batch_size, seq_len, max_len(của câu đầu ra)]\n",
    "\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        input = self.embedding(input)\n",
    "        input = F.relu(input)\n",
    "        output, hidden = self.rnn_layer(input, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Rnn tổng quát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnMachineTranslate(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(RnnMachineTranslate, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # x là 1 bacth các câu đầu vào\n",
    "        result_time_steps, context = self.encoder(x)\n",
    "        decoder_outputs, decoder_hidden = self.decoder(result_time_steps, context, y)\n",
    "\n",
    "        return decoder_outputs       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
